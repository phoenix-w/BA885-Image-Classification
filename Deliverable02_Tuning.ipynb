{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BA885 Team Project\n",
    "#### Christian Lawrence, Tianzheng Mao, Tiam Moradi, Phoenix Wang"
   ],
   "metadata": {
    "id": "SmOp1xwvLDcc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To access the dataset, please add the following shared folders to your working directory:\n",
    "* https://tinyurl.com/3cn2zk8u (labeled images)\n",
    "* https://tinyurl.com/ypaf8wtt (unlabeled images)"
   ],
   "metadata": {
    "id": "rX-EXrJsKJoz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Environment Setup"
   ],
   "metadata": {
    "id": "vgBH3kJeK-iT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow as tf\r\n",
    "import PIL\r\n",
    "import PIL.Image\r\n",
    "import pathlib\r\n",
    "import matplotlib.image as mpimg\r\n",
    "from matplotlib import rcParams\r\n",
    "from pathlib import Path\r\n",
    "import pathlib"
   ],
   "outputs": [],
   "metadata": {
    "id": "Iex9-JlhnxYs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Setup"
   ],
   "metadata": {
    "id": "oOdGukMWqk-F"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# # load all the labeled images\r\n",
    "# data_dir = pathlib.Path('Labeled')\r\n",
    "# print('Total number of labeled images:', len(list(data_dir.glob('*/*.jpg'))))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7WOiifcqjGj",
    "outputId": "4a98cbc5-5f90-41fa-8ac2-bd3cab5937e0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# # shape of each image\r\n",
    "# tf.keras.preprocessing.image.img_to_array(PIL.Image.open(str(building[0]))).shape"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnrkzDIBisHe",
    "outputId": "c4b32db2-f0fd-4d1f-b535-9e52da74e226"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "id": "AmYF3zmWqom6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use 80% of the images for training and 20% for validation."
   ],
   "metadata": {
    "id": "rp2cMlksj_IV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "batch_size = 32\r\n",
    "img_height = 150\r\n",
    "img_width = 150"
   ],
   "outputs": [],
   "metadata": {
    "id": "uHMf1DfcqsLR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# generate training set\r\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    data_dir,\r\n",
    "    validation_split=0.2,\r\n",
    "    subset=\"training\",\r\n",
    "    seed=885,\r\n",
    "    image_size=(img_height, img_width),\r\n",
    "    batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSFOi3vckmu1",
    "outputId": "9df98f2e-1608-47a9-ec6e-a603da20401d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# generate validation set\r\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    data_dir,\r\n",
    "    validation_split=0.2,\r\n",
    "    subset=\"validation\",\r\n",
    "    seed=885,\r\n",
    "    image_size=(img_height, img_width),\r\n",
    "    batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfLtKk4Rj5eC",
    "outputId": "f7ccd9f8-3104-4aea-d48a-8c40b1f4d1dc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each batch contains 32 images of shape `(150, 150, 3)` and their corresponding labels."
   ],
   "metadata": {
    "id": "7E4lG14Wl85n"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# shape of each batch\r\n",
    "image_batch, label_batch = next(iter(train_ds))\r\n",
    "print(image_batch.shape)\r\n",
    "print(label_batch.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 150, 150, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMvFiqIilMt8",
    "outputId": "344544e7-a29a-459f-bcbe-eea60791901f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rescaling"
   ],
   "metadata": {
    "id": "9R_OkiBkm7wF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The RGB channel values are in the `[0, 255]` range. We'll rescale the values to be in the `[0, 1]` range."
   ],
   "metadata": {
    "id": "ppAj2IsxnH3Q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# value range from 0 to 255\r\n",
    "image_batch, label_batch = next(iter(train_ds))\r\n",
    "print('Minimum value:', np.min(image_batch))\r\n",
    "print('Maximum value:', np.max(image_batch))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Minimum value: 0.0\n",
      "Maximum value: 255.0\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrB96JXoo4rH",
    "outputId": "aa4c05cc-e8d5-415e-fb12-fe50440e647f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "standardization = tf.keras.layers.experimental.preprocessing.Rescaling(1/255)\r\n",
    "train_ds = train_ds.map(lambda x, y: (standardization(x), y))\r\n",
    "val_ds = val_ds.map(lambda x, y: (standardization(x), y))"
   ],
   "outputs": [],
   "metadata": {
    "id": "LUk-IQ9MnJUk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# value range from 0 to 1\r\n",
    "image_batch, label_batch = next(iter(train_ds))\r\n",
    "print('Minimum value:', np.min(image_batch))\r\n",
    "print('Maximum value:', np.max(image_batch))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Minimum value: 0.0\n",
      "Maximum value: 1.0\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0GZD4PVoOP6",
    "outputId": "a4332c92-e359-4c51-f403-ba4f0baf7b38"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Building and Tuning"
   ],
   "metadata": {
    "id": "4Iqtdvo5pcDq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# configure performance\r\n",
    "AUTOTUNE = tf.data.AUTOTUNE\r\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\r\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {
    "id": "OUVXHaNQqOZP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "def build_model(hp):  \r\n",
    "  model = keras.Sequential([\r\n",
    "    keras.layers.Conv2D(\r\n",
    "        filters=hp.Int('conv_1_filter', min_value=16, max_value=64, step=16),\r\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,8]),\r\n",
    "        activation='relu'\r\n",
    "    ),\r\n",
    "    keras.layers.MaxPooling2D(),\r\n",
    "    keras.layers.Conv2D(\r\n",
    "        filters=hp.Int('conv_2_filter', min_value=16, max_value=64, step=16),\r\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\r\n",
    "        activation='relu'\r\n",
    "    ),\r\n",
    "    keras.layers.MaxPooling2D(),\r\n",
    "    keras.layers.Conv2D(\r\n",
    "        filters=hp.Int('conv_3_filter', min_value=8, max_value=16, step=2),\r\n",
    "        kernel_size=hp.Choice('conv_3_kernel', values = [3,5]),\r\n",
    "        activation='relu'\r\n",
    "    ),\r\n",
    "    keras.layers.MaxPooling2D(),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(\r\n",
    "        units=hp.Int('dense_1_units', min_value=8, max_value=16, step=2),\r\n",
    "        activation='relu'\r\n",
    "    ),\r\n",
    "    keras.layers.Dense(10, activation='softmax')\r\n",
    "  ])\r\n",
    "  \r\n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\r\n",
    "              loss='sparse_categorical_crossentropy',\r\n",
    "              metrics=['accuracy'])\r\n",
    "  \r\n",
    "  return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "4Ge7E5ZB-xGA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "import keras_tuner\r\n",
    "from kerastuner import RandomSearch\r\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\r\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xr-Ea__g-xOR",
    "outputId": "7b62f73d-9eec-461e-e91b-16ebee0ceb13"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "tuner_search=RandomSearch(build_model,\r\n",
    "                          objective='val_accuracy',\r\n",
    "                          max_trials=10,directory='output',project_name=\"BA_885\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV-jM3bE-xRx",
    "outputId": "36f67fa9-58cf-43bb-a73b-48e0f981f473"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2,min_delta=0.0001)\r\n",
    "tuner_search.search(train_ds, validation_data=val_ds,epochs=5,callbacks=[stop_early])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial 10 Complete [00h 00m 51s]\n",
      "val_accuracy: 0.17499999701976776\n",
      "\n",
      "Best val_accuracy So Far: 0.7360000014305115\n",
      "Total elapsed time: 00h 09m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8H40-Q9FDcpo",
    "outputId": "3c16194b-3ce7-4066-f54b-ad14632ac0be"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ],
   "outputs": [],
   "metadata": {
    "id": "EGFf1IxTDcsn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "model.build(image_batch.shape)\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (32, 143, 143, 32)        6176      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (32, 71, 71, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (32, 69, 69, 16)          4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (32, 34, 34, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (32, 30, 30, 14)          5614      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (32, 15, 15, 14)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (32, 3150)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 10)                  31510     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 10)                  110       \n",
      "=================================================================\n",
      "Total params: 48,034\n",
      "Trainable params: 48,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "id": "nQXzVx3cDgi1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "epochs = 10\r\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "439/439 [==============================] - 9s 19ms/step - loss: 0.5555 - accuracy: 0.7999 - val_loss: 0.6872 - val_accuracy: 0.7570\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.5058 - accuracy: 0.8193 - val_loss: 0.7581 - val_accuracy: 0.7450\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.4596 - accuracy: 0.8381 - val_loss: 0.7470 - val_accuracy: 0.7560\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.4289 - accuracy: 0.8490 - val_loss: 0.7900 - val_accuracy: 0.7517\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.3855 - accuracy: 0.8648 - val_loss: 0.9728 - val_accuracy: 0.7250\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.3723 - accuracy: 0.8674 - val_loss: 0.8593 - val_accuracy: 0.7470\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.3281 - accuracy: 0.8839 - val_loss: 0.8414 - val_accuracy: 0.7487\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.3192 - accuracy: 0.8853 - val_loss: 0.8593 - val_accuracy: 0.7573\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.2935 - accuracy: 0.8948 - val_loss: 0.9289 - val_accuracy: 0.7530\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 8s 19ms/step - loss: 0.2608 - accuracy: 0.9062 - val_loss: 0.9888 - val_accuracy: 0.7570\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ef7f6fa100>"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "phoenix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}